# %% [markdown]
# # üìö Sistem RAG dengan Gemini API untuk PDF
# 
# Sistem ini dapat:
# 1. Membaca file PDF dari upload
# 2. Mengolah dan menyimpan embedding
# 3. Berinteraksi dengan konten PDF menggunakan Gemini API
# 4. Menyimpan hasil ke GitHub

# %% [markdown]
# ## Instalasi Dependencies

# %%
!pip install -q pypdf langchain-google-genai chromadb pymupdf tiktoken python-dotenv streamlit-git
!pip install -q faiss-cpu
!pip install -q streamlit

# %% [markdown]
# ## Import Libraries

# %%
import os
import sys
import json
import pickle
import shutil
from pathlib import Path
from typing import List, Dict, Any, Optional
import tempfile
from datetime import datetime

# PDF Processing
from pypdf import PdfReader
import fitz  # PyMuPDF

# Vector Store
import chromadb
from chromadb.config import Settings
import numpy as np

# Gemini API
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI

# Utilities
from dotenv import load_dotenv
import hashlib
import warnings
warnings.filterwarnings('ignore')

# %% [markdown]
# ## Konfigurasi API Keys

# %%
# @title Masukkan API Key Gemini Anda
import getpass

# Upload file .env atau masukkan manual
GEMINI_API_KEY = getpass.getpass("Masukkan Gemini API Key: ")

# Atau upload file .env
from google.colab import files
uploaded = files.upload()

if 'env.txt' in uploaded:
    with open('env.txt', 'w') as f:
        f.write(uploaded['env.txt'].decode())
    load_dotenv('env.txt')
    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# Konfigurasi Gemini
genai.configure(api_key=GEMINI_API_KEY)

# %% [markdown]
# ## 1. Kelas PDF Processor

# %%
class PDFProcessor:
    """Kelas untuk memproses file PDF"""
    
    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        
    def extract_text_from_pdf(self, pdf_path: str) -> List[Dict[str, Any]]:
        """Ekstrak teks dari PDF dengan metadata"""
        documents = []
        
        try:
            # Menggunakan PyPDF
            reader = PdfReader(pdf_path)
            for page_num, page in enumerate(reader.pages, 1):
                text = page.extract_text()
                if text.strip():
                    documents.append({
                        'text': text,
                        'metadata': {
                            'source': pdf_path,
                            'page': page_num,
                            'total_pages': len(reader.pages)
                        }
                    })
        except Exception as e:
            print(f"Error dengan PyPDF: {e}, mencoba PyMuPDF...")
            
            # Fallback ke PyMuPDF
            doc = fitz.open(pdf_path)
            for page_num in range(len(doc)):
                page = doc[page_num]
                text = page.get_text()
                if text.strip():
                    documents.append({
                        'text': text,
                        'metadata': {
                            'source': pdf_path,
                            'page': page_num + 1,
                            'total_pages': len(doc)
                        }
                    })
            doc.close()
            
        return documents
    
    def chunk_documents(self, documents: List[Dict], chunk_size: int = None, 
                        chunk_overlap: int = None) -> List[Dict]:
        """Membagi dokumen menjadi chunk"""
        if chunk_size is None:
            chunk_size = self.chunk_size
        if chunk_overlap is None:
            chunk_overlap = self.chunk_overlap
            
        chunks = []
        
        for doc in documents:
            text = doc['text']
            metadata = doc['metadata']
            
            # Simple text splitting
            words = text.split()
            for i in range(0, len(words), chunk_size - chunk_overlap):
                chunk_words = words[i:i + chunk_size]
                chunk_text = ' '.join(chunk_words)
                
                chunks.append({
                    'text': chunk_text,
                    'metadata': {
                        **metadata,
                        'chunk_id': len(chunks),
                        'start_word': i,
                        'end_word': min(i + chunk_size, len(words))
                    }
                })
                
        return chunks

# %% [markdown]
# ## 2. Kelas Vector Store

# %%
class VectorStoreManager:
    """Manajemen vector store dengan ChromaDB"""
    
    def __init__(self, persist_dir: str = "./chroma_db"):
        self.persist_dir = persist_dir
        self.embeddings = None
        self.client = None
        self.collection = None
        
    def initialize_embeddings(self, api_key: str):
        """Inisialisasi embeddings model"""
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=api_key
        )
    
    def create_collection(self, collection_name: str = "pdf_documents"):
        """Membuat atau load collection"""
        self.client = chromadb.PersistentClient(path=self.persist_dir)
        
        try:
            self.collection = self.client.get_collection(name=collection_name)
            print(f"Loaded existing collection: {collection_name}")
        except:
            self.collection = self.client.create_collection(
                name=collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            print(f"Created new collection: {collection_name}")
    
    def add_documents(self, chunks: List[Dict]):
        """Menambahkan dokumen ke vector store"""
        if not self.collection:
            raise ValueError("Collection belum diinisialisasi")
            
        documents = []
        metadatas = []
        ids = []
        
        for idx, chunk in enumerate(chunks):
            documents.append(chunk['text'])
            metadatas.append(chunk['metadata'])
            
            # Generate unique ID
            chunk_hash = hashlib.md5(
                f"{chunk['metadata']['source']}_{chunk['metadata']['page']}_{idx}".encode()
            ).hexdigest()
            ids.append(chunk_hash)
        
        self.collection.add(
            documents=documents,
            metadatas=metadatas,
            ids=ids
        )
        print(f"Added {len(documents)} chunks to vector store")
    
    def search_similar(self, query: str, k: int = 5) -> List[Dict]:
        """Search similar documents"""
        if not self.embeddings:
            raise ValueError("Embeddings belum diinisialisasi")
            
        # Get query embedding
        query_embedding = self.embeddings.embed_query(query)
        
        # Search in collection
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=k,
            include=["documents", "metadatas", "distances"]
        )
        
        formatted_results = []
        if results['documents']:
            for i in range(len(results['documents'][0])):
                formatted_results.append({
                    'text': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'score': results['distances'][0][i]
                })
        
        return formatted_results

# %% [markdown]
# ## 3. Kelas RAG System

# %%
class RAGSystem:
    """Sistem RAG utama"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.pdf_processor = PDFProcessor()
        self.vector_store = VectorStoreManager()
        self.llm = None
        self.initialize_models()
    
    def initialize_models(self):
        """Inisialisasi semua model"""
        # Initialize embeddings
        self.vector_store.initialize_embeddings(self.api_key)
        self.vector_store.create_collection()
        
        # Initialize LLM
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-pro",
            google_api_key=self.api_key,
            temperature=0.7,
            convert_system_message_to_human=True
        )
    
    def process_pdfs(self, pdf_paths: List[str]):
        """Proses multiple PDF files"""
        all_chunks = []
        
        for pdf_path in pdf_paths:
            print(f"Processing: {pdf_path}")
            
            # Extract text
            documents = self.pdf_processor.extract_text_from_pdf(pdf_path)
            print(f"  Extracted {len(documents)} pages")
            
            # Chunk documents
            chunks = self.pdf_processor.chunk_documents(documents)
            print(f"  Created {len(chunks)} chunks")
            
            all_chunks.extend(chunks)
        
        # Add to vector store
        self.vector_store.add_documents(all_chunks)
        return len(all_chunks)
    
    def query(self, question: str, k: int = 5) -> Dict[str, Any]:
        """Query system dengan RAG"""
        # Search similar documents
        similar_docs = self.vector_store.search_similar(question, k=k)
        
        if not similar_docs:
            return {
                'answer': "Tidak ditemukan informasi relevan dalam dokumen.",
                'sources': []
            }
        
        # Build context
        context = "\n\n".join([
            f"[Dokumen {i+1}, Halaman {doc['metadata']['page']}]: {doc['text']}"
            for i, doc in enumerate(similar_docs)
        ])
        
        # Create prompt
        prompt = f"""Berdasarkan konteks berikut, jawab pertanyaan dengan detail.
        Jika tidak ada informasi yang cukup dalam konteks, katakan bahwa Anda tidak tahu.

KONTEKS:
{context}

PERTANYAAN: {question}

JAWABAN:"""
        
        try:
            # Get response from Gemini
            response = self.llm.invoke(prompt)
            answer = response.content if hasattr(response, 'content') else str(response)
        except Exception as e:
            answer = f"Error mendapatkan respons: {str(e)}"
        
        # Format sources
        sources = []
        for doc in similar_docs:
            sources.append({
                'page': doc['metadata']['page'],
                'source': os.path.basename(doc['metadata']['source']),
                'text_preview': doc['text'][:100] + "..."
            })
        
        return {
            'answer': answer,
            'sources': sources,
            'context_used': [doc['text'] for doc in similar_docs]
        }
    
    def save_to_github_format(self, output_dir: str = "./github_output"):
        """Save processed data in GitHub friendly format"""
        os.makedirs(output_dir, exist_ok=True)
        
        # Save metadata
        metadata = {
            'processed_date': datetime.now().isoformat(),
            'vector_store_path': self.vector_store.persist_dir,
            'embeddings_model': 'models/embedding-001',
            'llm_model': 'gemini-pro'
        }
        
        with open(f"{output_dir}/metadata.json", 'w') as f:
            json.dump(metadata, f, indent=2)
        
        # Save example queries
        example_queries = [
            "Apa topik utama dari dokumen ini?",
            "Siapa penulis dokumen ini?",
            "Jelaskan poin-poin penting dari dokumen ini.",
            "Apa kesimpulan dari dokumen ini?"
        ]
        
        with open(f"{output_dir}/example_queries.txt", 'w') as f:
            for query in example_queries:
                f.write(f"- {query}\n")
        
        print(f"Data saved to {output_dir}")
        return output_dir

# %% [markdown]
# ## 4. Upload dan Proses PDF

# %%
# @title Upload PDF Files
from google.colab import files

print("Upload PDF files (select multiple with Ctrl+Click)")
uploaded_files = files.upload()

# Save uploaded files
pdf_paths = []
for filename, content in uploaded_files.items():
    if filename.lower().endswith('.pdf'):
        with open(filename, 'wb') as f:
            f.write(content)
        pdf_paths.append(filename)
        print(f"Saved: {filename}")

# %% [markdown]
# ## 5. Inisialisasi dan Proses RAG

# %%
# Initialize RAG system
rag_system = RAGSystem(GEMINI_API_KEY)

# Process PDFs
if pdf_paths:
    total_chunks = rag_system.process_pdfs(pdf_paths)
    print(f"\n‚úÖ Processing complete! Total chunks: {total_chunks}")
else:
    print("No PDF files uploaded!")

# %% [markdown]
# ## 6. Interactive Chat Interface

# %%
# @title Chat with Your PDFs

def chat_interface():
    """Simple chat interface"""
    print("=" * 60)
    print("ü§ñ RAG PDF Chat System")
    print("=" * 60)
    print("Type 'quit' to exit")
    print("Type 'sources' to show last sources")
    print("=" * 60)
    
    history = []
    
    while True:
        question = input("\nüí¨ Question: ").strip()
        
        if question.lower() == 'quit':
            break
        elif question.lower() == 'sources':
            if history:
                last_response = history[-1]
                print("\nüìö Last sources:")
                for i, source in enumerate(last_response['sources'], 1):
                    print(f"{i}. {source['source']} - Page {source['page']}")
                    print(f"   Preview: {source['text_preview']}")
            continue
        
        if not question:
            continue
        
        print("\nüîç Searching...")
        
        try:
            response = rag_system.query(question)
            
            print(f"\nüìù Answer:\n{response['answer']}")
            
            if response['sources']:
                print(f"\nüìö Sources ({len(response['sources'])}):")
                for i, source in enumerate(response['sources'][:3], 1):
                    print(f"{i}. {source['source']} - Page {source['page']}")
            
            history.append(response)
            
        except Exception as e:
            print(f"‚ùå Error: {str(e)}")

# Run chat interface
if 'rag_system' in locals() and pdf_paths:
    chat_interface()

# %% [markdown]
# ## 7. Save for GitHub Deployment

# %%
# @title Prepare for GitHub Deployment

# Create GitHub ready files
github_dir = rag_system.save_to_github_format()

# Create requirements.txt
requirements = """
streamlit==1.28.1
pypdf==3.17.1
langchain-google-genai==0.0.6
chromadb==0.4.18
pymupdf==1.23.8
python-dotenv==1.0.0
google-generativeai==0.3.2
faiss-cpu==1.7.4
"""

with open(f"{github_dir}/requirements.txt", 'w') as f:
    f.write(requirements)

# Create a simple test script
test_script = """
import streamlit as st
import os
from pathlib import Path

st.title("PDF RAG System Test")
st.write("This is a placeholder for the RAG system.")

# File uploader
uploaded_files = st.file_uploader(
    "Upload PDF files", 
    type=['pdf'], 
    accept_multiple_files=True
)

if uploaded_files:
    st.success(f"Uploaded {len(uploaded_files)} files")
    
    for file in uploaded_files:
        st.write(f"- {file.name}")
"""

with open(f"{github_dir}/test_app.py", 'w') as f:
    f.write(test_script)

print(f"\n‚úÖ GitHub files prepared in: {github_dir}")
print("Contents:")
for file in os.listdir(github_dir):
    print(f"  - {file}")

# Download zip for GitHub
!zip -r rag_system.zip {github_dir}

print("\nüì¶ Download 'rag_system.zip' for GitHub upload")
